{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the library\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3efffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train = pd.read_csv('4910797b-ee55-40a7-8668-10efd5c1b960.csv')\n",
    "label = pd.read_csv('0bf8bc6e-30d0-4c50-956a-603fc693d966.csv')\n",
    "test = pd.read_csv('702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32436c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b03005",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b62fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aaf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7a713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab91055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the train with the label of the data\n",
    "data = train.merge(label, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rate = data.isna().sum()/len(data)\n",
    "null_rate.sort_values(ascending= False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rates = test.isna().sum()/len(test)\n",
    "null_rates.sort_values(ascending= False).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713dd1e9",
   "metadata": {},
   "source": [
    "scheme_name variable contains most null values, so we need to find what is inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['scheme_name', 'scheme_management', 'installer', 'funder', 'public_meeting', 'permit', 'subvillage']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9ddad",
   "metadata": {},
   "source": [
    "there are to many distinct count of unique values of scheme_name, installer, funder, and subvillage. so we need to drop the columns and fill the rest null columns with the mode of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1042ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['permit'] = data['permit'].fillna(data['permit'].mode()[0])\n",
    "data['public_meeting'] = data['public_meeting'].fillna(data['public_meeting'].mode()[0])\n",
    "data['scheme_management'] = data['scheme_management'].fillna('Other')\n",
    "\n",
    "test['permit'] = data['permit'].fillna(data['permit'].mode()[0])\n",
    "test['public_meeting'] = data['public_meeting'].fillna(data['public_meeting'].mode()[0])\n",
    "test['scheme_management'] = data['scheme_management'].fillna('Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['scheme_name', 'installer', 'funder', 'subvillage'], inplace= True)\n",
    "test.drop(columns = ['scheme_name', 'installer', 'funder', 'subvillage'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes('object').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['wpt_name', 'ward'], axis=1, inplace=True)\n",
    "test.drop(['wpt_name', 'ward'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date_recorded'] = pd.to_datetime(data['date_recorded'])\n",
    "data['year'] = data['date_recorded'].dt.year\n",
    "data['month'] = data['date_recorded'].dt.month\n",
    "data['date'] = data['date_recorded'].dt.day\n",
    "data.drop('date_recorded', axis=1, inplace=True)\n",
    "\n",
    "test['date_recorded'] = pd.to_datetime(test['date_recorded'])\n",
    "test['year'] = test['date_recorded'].dt.year\n",
    "test['month'] = test['date_recorded'].dt.month\n",
    "test['date'] = test['date_recorded'].dt.day\n",
    "test.drop('date_recorded', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # the data is imbalanced, so i will do the data oversampling and undersampling\n",
    "func = data[data['status_group']=='functional']\n",
    "no_func = data[data['status_group']=='non functional']\n",
    "repair = data[data['status_group']=='functional needs repair']\n",
    "\n",
    "print(func.shape)\n",
    "print(no_func.shape)\n",
    "print(repair.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = func.sample(22824)\n",
    "repair = repair.sample(22824, replace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(func['status_group'].value_counts())\n",
    "print(no_func['status_group'].value_counts())\n",
    "print(repair['status_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have same number for each status, let's concat into one dataframe\n",
    "train_data = pd.concat([func, no_func, repair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca186ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the feature and label\n",
    "x = train_data.drop('status_group', axis=1)\n",
    "y = train_data['status_group'].map({'functional':0, 'non functional':1, 'functional needs repair':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fe4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b26c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting categorical feature for catboost and label encode (other models)\n",
    "cat_features = np.where(data.select_dtypes('object'))[1]\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c865d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where(x.dtypes == np.object)[0]\n",
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating catboost model\n",
    "model=CatBoostClassifier(iterations=200, depth=3, loss_function= 'MultiClass',learning_rate=0.05,train_dir= 'crossentropy',\n",
    "    allow_writing_files= False, random_seed= 42)\n",
    "model.fit(x_train, y_train, cat_features= categorical_features_indices, eval_set=(x_val, y_val),plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7429e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ff316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the accuracy of this model\n",
    "print(accuracy_score(prediction, y_val))\n",
    "class_names = ['functional','non-functional','needs repair']\n",
    "disp = plot_confusion_matrix(model, x_val, y_val,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ed7aa",
   "metadata": {},
   "source": [
    "from the result, we can see catboost model gain <70% accuracy, now we will try another models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e82c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data for other models\n",
    "x = train_data.drop('status_group', axis=1)\n",
    "y = train_data['status_group'].map({'functional':0, 'non functional':1, 'functional needs repair':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some machine learning models\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab3f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc759a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x.select_dtypes('object').columns\n",
    "x_train[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode each categorical columns\n",
    "le = LabelEncoder()\n",
    "for column in cat_features:\n",
    "    x[column] = le.fit_transform(x[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b70b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and scale the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "le = LabelEncoder()\n",
    "for column in cat_features:\n",
    "    x[column] = le.fit_transform(x[column])\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d54786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating models\n",
    "models = []\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(n_estimators=900, max_depth=20)))\n",
    "models.append(('BaggingClassifier', BaggingClassifier(DecisionTreeClassifier(max_depth=20), \n",
    "               n_estimators= 500, bootstrap=True, random_state=1)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier(n_neighbors=9)))\n",
    "models.append(('GaussianNB', GaussianNB()))\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('XGBClassifier', XGBClassifier()))\n",
    "models.append(('LogisticRegression', LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff094ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict the train dataset\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    model.fit(x_train, y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    print(accuracy_score(y_test, prediction))\n",
    "\n",
    "    disp = plot_confusion_matrix(model, x_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2436a",
   "metadata": {},
   "source": [
    "from the result above we can see that Random Forest Classifier gain the highest accuracy, so we will use it to predict our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and scaling the test data \n",
    "for column in cat_features:\n",
    "    test[column] = le.fit_transform(test[column])\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ba06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction for the test dataset\n",
    "predictions = models[0][1].predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b15c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new dataset that contain only id and the label\n",
    "test = pd.read_csv('702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv')\n",
    "submission = test[['id']]\n",
    "submission['status_group'] = predictions\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the encoded label into original name\n",
    "submission['status_group'] = submission['status_group'].map({0:'functional', 1:'non functional', 2:'functional needs repair'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b4053",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the result\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de939af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
